{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "import dateutil\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.date.today()\n",
    "start = end - relativedelta(years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2021', '4'],\n",
       " ['2021', '5'],\n",
       " ['2021', '6'],\n",
       " ['2021', '7'],\n",
       " ['2021', '8'],\n",
       " ['2021', '9'],\n",
       " ['2021', '10'],\n",
       " ['2021', '11'],\n",
       " ['2021', '12'],\n",
       " ['2022', '1'],\n",
       " ['2022', '2'],\n",
       " ['2022', '3']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_in_range = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %#m\").tolist()]\n",
    "months_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your api key environment variable\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"NEWS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(date):\n",
    "    '''Sends a request to the NYT Archive API for given date.'''\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + api_key\n",
    "    response = requests.get(url).json()\n",
    "    time.sleep(6)\n",
    "    return response\n",
    "\n",
    "\n",
    "def is_valid(article, date):\n",
    "    '''An article is only worth checking if it is in range, and has a headline.'''\n",
    "    is_in_range = date > start and date < end\n",
    "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
    "    return is_in_range and has_headline\n",
    "\n",
    "\n",
    "def parse_response(response):\n",
    "    '''Parses and returns response as pandas data frame.'''\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "        'doc_type': [],\n",
    "        'material_type': [],\n",
    "        'section': [],\n",
    "        'keywords': []}\n",
    "    \n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: # For each article, make sure it falls within our date range\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        if is_valid(article, date):\n",
    "            data['date'].append(date)\n",
    "            data['headline'].append(article['headline']['main']) \n",
    "            if 'section' in article:\n",
    "                data['section'].append(article['section_name'])\n",
    "            else:\n",
    "                data['section'].append(None)\n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            if 'type_of_material' in article: \n",
    "                data['material_type'].append(article['type_of_material'])\n",
    "            else:\n",
    "                data['material_type'].append(None)\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "    return pd.DataFrame(data) \n",
    "\n",
    "\n",
    "def get_data(dates):\n",
    "    '''Sends and parses request/response to/from NYT Archive API for given dates.'''\n",
    "    total = 0\n",
    "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
    "    if not os.path.exists('headlines'):\n",
    "        os.mkdir('headlines')\n",
    "    for date in dates:\n",
    "        response = send_request(date)\n",
    "        df = parse_response(response)\n",
    "        total += len(df)\n",
    "        df.to_csv('headlines/' + date[0] + '-' + date[1] + '.csv', index=False)\n",
    "        print('Saving headlines/' + date[0] + '-' + date[1] + '.csv...')\n",
    "    print('Number of articles collected: ' + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: ['2021', '4'] to ['2022', '3']\n",
      "Saving headlines/2021-4.csv...\n",
      "Saving headlines/2021-5.csv...\n",
      "Saving headlines/2021-6.csv...\n",
      "Saving headlines/2021-7.csv...\n",
      "Saving headlines/2021-8.csv...\n",
      "Saving headlines/2021-9.csv...\n",
      "Saving headlines/2021-10.csv...\n",
      "Saving headlines/2021-11.csv...\n",
      "Saving headlines/2021-12.csv...\n",
      "Saving headlines/2022-1.csv...\n",
      "Saving headlines/2022-2.csv...\n",
      "Saving headlines/2022-3.csv...\n",
      "Number of articles collected: 47861\n"
     ]
    }
   ],
   "source": [
    "get_data(months_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "os.chdir(\"headlines\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
